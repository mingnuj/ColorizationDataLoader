{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColorHint Dataloader.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BQmYo2rqmK4"
      },
      "source": [
        "# Get Dataset from Google Drive  \n",
        "Please upload your dataset on google drive first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vxHB3wfW911",
        "outputId": "a99a8768-2ed9-4576-c198-44f900b0f089"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmbp65jgq67j"
      },
      "source": [
        "# Color-hint Transform\n",
        "\n",
        "If you want to change how many hints you are giving, change the threshold values in __call__ function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyeUBdtKYQSu"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class ColorHintTransform(object):\n",
        "  def __init__(self, size=256, mode=\"training\"):\n",
        "    super(ColorHintTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "    self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  def bgr_to_lab(self, img):\n",
        "      lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "      l, ab = lab[:, :, 0], lab[:, :, 1:]\n",
        "      return l, ab\n",
        "  \n",
        "  def hint_mask(self, bgr, threshold=[0.95, 0.97, 0.99]):\n",
        "    h, w, c = bgr.shape\n",
        "    mask_threshold = random.choice(threshold)\n",
        "    mask = np.random.random([h, w, 1]) > threshold\n",
        "    return mask\n",
        "\n",
        "  def __call__(self, img):\n",
        "    threshold = [0.95, 0.97, 0.99]\n",
        "    if (self.mode == \"training\") | (self.mode == \"validation\"):\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "      mask = self.hint_mask(image, threshold)\n",
        "\n",
        "      hint_image = image * mask\n",
        "      \n",
        "      l, ab = self.bgr_to_lab(image)\n",
        "      l_hint, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "      return self.transform(l), self.transform(ab), self.transform(ab_hint)\n",
        "\n",
        "    elif self.mode == \"testing\":\n",
        "      image = cv2.resize(img, (self.size, self.size))\n",
        "\n",
        "      l, ab = self.bgr_to_lab(image)\n",
        "\n",
        "      return self.gt_transform(l), self.transform(ab)\n",
        "\n",
        "    else:\n",
        "      return NotImplementedError\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGKbE7uFrWwb"
      },
      "source": [
        "# Dataloader for Colorization Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxZsXXZ9YpYp"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "class ColorHintDataset(data.Dataset):\n",
        "  def __init__(self, root_path, size):\n",
        "    super(ColorHintDataset, self).__init__()\n",
        " \n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.transforms = None\n",
        "    self.examples = None\n",
        " \n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = ColorHintTransform(self.size, mode)\n",
        "    if mode == \"training\":\n",
        "      train_dir = os.path.join(self.root_path, \"train\")\n",
        "      self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "    elif mode == \"validation\":\n",
        "      val_dir = os.path.join(self.root_path, \"validation\")\n",
        "      self.examples = [os.path.join(self.root_path, \"validation\", dirs) for dirs in os.listdir(val_dir)]\n",
        "    elif mode == \"testing\":\n",
        "      test_dir = os.path.join(self.root_path, \"test\")\n",
        "      self.examples = [os.path.join(self.root_path, \"test\", dirs) for dirs in os.listdir(test_dir)]\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        " \n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.examples[idx]\n",
        "    img = cv2.imread(file_name)\n",
        "\n",
        "    if self.mode == \"testing\":\n",
        "      input_l, input_ab = self.transforms(img)\n",
        "      sample = {\"l\": input_l, \"ab\": input_ab}\n",
        "    else:\n",
        "      l, ab, hint = self.transforms(img)\n",
        "      sample = {\"l\": l, \"ab\": ab, \"hint\": hint}\n",
        " \n",
        "    return sample"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDx4vFU-rf5z"
      },
      "source": [
        "# Example for Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53tDtBFLenTz"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data  as data\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "  if isinstance(input_image, torch.Tensor):\n",
        "      image_tensor = input_image.data\n",
        "  else:\n",
        "      return input_image\n",
        "  image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "  if image_numpy.shape[0] == 1:\n",
        "      image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "  image_numpy = np.clip((np.transpose(image_numpy, (1, 2, 0)) ),0, 1) * 255.0\n",
        "  return image_numpy.astype(imtype)\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"/content/drive/MyDrive/Multimedia_dataset\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "\n",
        "train_dataset = ColorHintDataset(root_path, 256)\n",
        "train_dataset.set_mode(\"training\")\n",
        "\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "  if use_cuda:\n",
        "    l = data[\"l\"]\n",
        "    ab = data[\"ab\"]\n",
        "    hint = data[\"hint\"]\n",
        "  \n",
        "  gt_image = torch.cat((l, ab), dim=1)\n",
        "  hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "  gt_np = tensor2im(gt_image)\n",
        "  hint_np = tensor2im(hint_image)\n",
        "\n",
        "  gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2BGR)\n",
        "  hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2BGR)\n",
        "  \n",
        "  cv2_imshow(gt_bgr)\n",
        "  cv2_imshow(hint_bgr)\n",
        "\n",
        "  input()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6dRxa3I7iwW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
